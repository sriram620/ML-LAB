{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2_hx0aLCLYW",
        "outputId": "de3ef7ad-f03d-4b9a-fff8-e6614bdfa354"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Specific Hypothesis (S): [np.str_('High'), '?', '?']\n",
            "Most General Hypothesis (G): [np.str_('High'), '?', '?']\n"
          ]
        }
      ],
      "source": [
        "#EX.NO:1\n",
        "#use case:Candidate Elimination Algorithm (Medical Diagnosis example)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Dataset: Fever, Cough, Fatigue, Disease\n",
        "data = np.array([\n",
        "    ['High', 'Yes', 'Yes', 'Yes'],\n",
        "    ['High', 'Yes', 'No',  'Yes'],\n",
        "    ['Normal', 'Yes', 'Yes', 'No'],\n",
        "    ['High', 'No',  'Yes', 'Yes']\n",
        "])\n",
        "\n",
        "X = data[:, :-1]\n",
        "Y = data[:, -1]\n",
        "\n",
        "# Initialize S and G\n",
        "S = ['Ø'] * len(X[0])\n",
        "G = ['?'] * len(X[0])\n",
        "\n",
        "for i, x in enumerate(X):\n",
        "    if Y[i] == 'Yes':\n",
        "        for j in range(len(S)):\n",
        "            if S[j] == 'Ø':\n",
        "                S[j] = x[j]\n",
        "            elif S[j] != x[j]:\n",
        "                S[j] = '?'\n",
        "    else:\n",
        "        for j in range(len(G)):\n",
        "            if x[j] != S[j]:\n",
        "                G[j] = S[j]\n",
        "\n",
        "print(\"Most Specific Hypothesis (S):\", S)\n",
        "print(\"Most General Hypothesis (G):\", G)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#EX.NO:2\n",
        "#USE CASE:ID3 Algorithm (Medical Diagnosis)\n",
        "\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "# Dataset\n",
        "data = {\n",
        "    'Fever': ['High', 'High', 'Normal', 'Low'],\n",
        "    'Cough': ['Yes', 'Yes', 'Yes', 'No'],\n",
        "    'Fatigue': ['Yes', 'No', 'Yes', 'No'],\n",
        "    'Age': ['Old', 'Young', 'Old', 'Young'],\n",
        "    'Disease': ['Yes', 'Yes', 'Yes', 'No']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Entropy function\n",
        "def entropy(target):\n",
        "    values = target.value_counts()\n",
        "    total = len(target)\n",
        "    ent = 0\n",
        "    for v in values:\n",
        "        p = v / total\n",
        "        ent -= p * math.log2(p)\n",
        "    return ent\n",
        "\n",
        "# Information Gain\n",
        "def info_gain(df, attr, target):\n",
        "    total_entropy = entropy(df[target])\n",
        "    values = df[attr].unique()\n",
        "    weighted_entropy = 0\n",
        "    for v in values:\n",
        "        subset = df[df[attr] == v]\n",
        "        weighted_entropy += (len(subset)/len(df)) * entropy(subset[target])\n",
        "    return total_entropy - weighted_entropy\n",
        "\n",
        "# Calculate Information Gain\n",
        "for column in df.columns[:-1]:\n",
        "    print(\"Information Gain of\", column, \"=\", round(info_gain(df, column, 'Disease'), 3))\n",
        "\n",
        "# Root attribute\n",
        "gains = {col: info_gain(df, col, 'Disease') for col in df.columns[:-1]}\n",
        "root = max(gains, key=gains.get)\n",
        "\n",
        "print(\"\\nBest Attribute (Root Node):\", root)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJG0izEwCsgu",
        "outputId": "df64971e-8779-4466-f6ea-8ae32d35e3a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Information Gain of Fever = 0.811\n",
            "Information Gain of Cough = 0.811\n",
            "Information Gain of Fatigue = 0.311\n",
            "Information Gain of Age = 0.311\n",
            "\n",
            "Best Attribute (Root Node): Fever\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#EX.NO:3\n",
        "#USE CASE:ANN with Backpropagation (Digit Recognition)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "# Load dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize data\n",
        "x_train, x_test = x_train/255.0, x_test/255.0\n",
        "\n",
        "# Build Model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28,28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "model.fit(x_train, y_train, epochs=3)\n",
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate(x_test, y_test)\n",
        "print(\"Test Accuracy:\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDMnfABPC84K",
        "outputId": "b6eac8ac-7679-41b8-9389-d8c0468db513"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8778 - loss: 0.4378\n",
            "Epoch 2/3\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9641 - loss: 0.1194\n",
            "Epoch 3/3\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9761 - loss: 0.0801\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.1040\n",
            "Test Accuracy: 0.9721999764442444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#EX.NO:5\n",
        "#USE CASE:Gaussian Naive Bayes (Email Spam Classification)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Dataset\n",
        "data = {\n",
        "    'Free':  [1,1,0,0,0,1],\n",
        "    'Win':   [1,0,1,0,0,0],\n",
        "    'Offer': [1,1,0,1,0,0],\n",
        "    'Spam':  [1,1,1,0,0,0]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "X = df[['Free','Win','Offer']]\n",
        "y = df['Spam']\n",
        "\n",
        "# Model\n",
        "model = GaussianNB()\n",
        "model.fit(X, y)\n",
        "\n",
        "# New Email: Free=Yes, Win=Yes, Offer=No\n",
        "prediction = model.predict([[1,1,0]])\n",
        "\n",
        "print(\"Predicted Class (1=Spam, 0=Not Spam):\", prediction[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXKudkcxDWoO",
        "outputId": "0eeb98e2-b311-43bc-f6da-979e7d6bfd74"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class (1=Spam, 0=Not Spam): 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}